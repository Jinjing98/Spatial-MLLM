{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9165d880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Suppress NVML warnings in Jupyter\n",
    "os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message='.*NVML.*')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message=\".*Can't initialize NVML.*\")\n",
    "\n",
    "# Add project root and vggt paths\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "sys.path.insert(0, str(project_root / \"src\" / \"qwenvl\" / \"external\"))\n",
    "\n",
    "# Import torch first\n",
    "import torch\n",
    "\n",
    "# Import from spatial_mllm\n",
    "from src.qwenvl.model.spatial_mllm import SpatialMLLMConfig, SpatialMLLMForConditionalGeneration\n",
    "\n",
    "# Register for autoreload\n",
    "%aimport src.qwenvl.model.spatial_mllm\n",
    "%aimport src.qwenvl.model.spatial_encoder\n",
    "%aimport src.qwenvl.model.connector\n",
    "\n",
    "print(f\"✓ Imports successful\")\n",
    "print(f\"✓ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ GPU device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee7a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize config and model\n",
    "config = SpatialMLLMConfig()\n",
    "model = SpatialMLLMForConditionalGeneration(config)\n",
    "\n",
    "# Move to CUDA if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Create dummy inputs with correct shapes\n",
    "batch_size = 1\n",
    "seq_length = 10\n",
    "\n",
    "input_ids = torch.randint(0, config.vocab_size, (batch_size, seq_length), device=device)\n",
    "attention_mask = torch.ones(batch_size, seq_length, device=device, dtype=torch.long)\n",
    "position_ids = torch.arange(seq_length, device=device).unsqueeze(0).expand(batch_size, -1)\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        input_ids=input_ids, \n",
    "        attention_mask=attention_mask, \n",
    "        position_ids=position_ids\n",
    "    )\n",
    "\n",
    "print(f\"Output logits shape: {outputs.logits.shape}\")\n",
    "print(f\"Config vocab_size: {config.vocab_size}\")\n",
    "print(f\"Device: {device}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial-mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
